{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c7e1c7850d81>:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(lis):\n",
    "    for l in lis:\n",
    "        os.mkdir(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data_dir = '../data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/experiment/'\n",
    "# os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir,'train')\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "# create_folders([train_dir,test_dir,validation_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats_dir = os.path.join(train_dir,'cats')\n",
    "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
    "test_cats_dir = os.path.join(test_dir,'cats')\n",
    "test_dogs_dir = os.path.join(test_dir,'dogs')\n",
    "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir,'dogs')\n",
    "# create_folders([train_cats_dir,train_dogs_dir,test_cats_dir,test_dogs_dir,validation_cats_dir,validation_dogs_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['cat.{}.jpg'.format(i) for i in range(2000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    src = os.path.join(org_data_dir,fname)\n",
    "    dst = os.path.join(train_cats_dir,fname)\n",
    "    shutil.copy(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['cat.{}.jpg'.format(i) for i in range(2000,2500)]\n",
    "\n",
    "for fname in fnames:\n",
    "    src = os.path.join(org_data_dir,fname)\n",
    "    dst = os.path.join(validation_cats_dir,fname)\n",
    "    shutil.copy(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['cat.{}.jpg'.format(i) for i in range(2500,3000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    src = os.path.join(org_data_dir,fname)\n",
    "    dst = os.path.join(test_cats_dir,fname)\n",
    "    shutil.copy(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['dog.{}.jpg'.format(i) for i in range(2000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    src = os.path.join(org_data_dir,fname)\n",
    "    dst = os.path.join(train_dogs_dir,fname)\n",
    "    shutil.copy(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['dog.{}.jpg'.format(i) for i in range(2000,2500)]\n",
    "\n",
    "for fname in fnames:\n",
    "    src = os.path.join(org_data_dir,fname)\n",
    "    dst = os.path.join(validation_dogs_dir,fname)\n",
    "    shutil.copy(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['dog.{}.jpg'.format(i) for i in range(2500,3000)]\n",
    "\n",
    "for fname in fnames:\n",
    "    src = os.path.join(org_data_dir,fname)\n",
    "    dst = os.path.join(test_dogs_dir,fname)\n",
    "    shutil.copy(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-78f884b5c1a9>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=0.0001),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 20)      560       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        5792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 865,105\n",
      "Trainable params: 865,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 47s 318ms/step - loss: 0.6947 - acc: 0.4890 - val_loss: 0.6898 - val_acc: 0.5000\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 54s 673ms/step - loss: 0.6829 - acc: 0.5435 - val_loss: 0.6626 - val_acc: 0.6250\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 14s 176ms/step - loss: 0.6640 - acc: 0.5889 - val_loss: 0.6432 - val_acc: 0.6370\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 12s 153ms/step - loss: 0.6522 - acc: 0.6359 - val_loss: 0.6455 - val_acc: 0.6180\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 0.6425 - acc: 0.6349 - val_loss: 0.6228 - val_acc: 0.6540\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 12s 143ms/step - loss: 0.6232 - acc: 0.6399 - val_loss: 0.6513 - val_acc: 0.6060\n",
      "Epoch 7/30\n",
      "80/80 [==============================] - 18s 225ms/step - loss: 0.6053 - acc: 0.6800 - val_loss: 0.5913 - val_acc: 0.6880\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.6107 - acc: 0.6653 - val_loss: 0.5918 - val_acc: 0.6930\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 14s 172ms/step - loss: 0.6108 - acc: 0.6653 - val_loss: 0.6032 - val_acc: 0.6650\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 13s 165ms/step - loss: 0.6068 - acc: 0.6820 - val_loss: 0.5702 - val_acc: 0.7060\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 11s 131ms/step - loss: 0.5784 - acc: 0.7034 - val_loss: 0.5775 - val_acc: 0.7060\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.5708 - acc: 0.6916 - val_loss: 0.5570 - val_acc: 0.7190\n",
      "Epoch 13/30\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.5600 - acc: 0.7276 - val_loss: 0.5496 - val_acc: 0.7120\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 0.5656 - acc: 0.7078 - val_loss: 0.5423 - val_acc: 0.7290\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.5607 - acc: 0.7027 - val_loss: 0.5405 - val_acc: 0.7200\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 0.4966 - acc: 0.7609 - val_loss: 0.5346 - val_acc: 0.7140\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 0.5131 - acc: 0.7569 - val_loss: 0.6145 - val_acc: 0.6670\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.5256 - acc: 0.7277 - val_loss: 0.5356 - val_acc: 0.7230\n",
      "Epoch 19/30\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.5224 - acc: 0.7368 - val_loss: 0.5206 - val_acc: 0.7350\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.4940 - acc: 0.7696 - val_loss: 0.5113 - val_acc: 0.7470\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 9s 116ms/step - loss: 0.4783 - acc: 0.7745 - val_loss: 0.5347 - val_acc: 0.7270\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.4879 - acc: 0.7598 - val_loss: 0.5055 - val_acc: 0.7460\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.4870 - acc: 0.7526 - val_loss: 0.4939 - val_acc: 0.7600\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.4707 - acc: 0.7807 - val_loss: 0.5168 - val_acc: 0.7390\n",
      "Epoch 25/30\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.4706 - acc: 0.7858 - val_loss: 0.5585 - val_acc: 0.7100\n",
      "Epoch 26/30\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.4664 - acc: 0.7741 - val_loss: 0.4911 - val_acc: 0.7620\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.4314 - acc: 0.8171 - val_loss: 0.5282 - val_acc: 0.7390\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 9s 113ms/step - loss: 0.4408 - acc: 0.8075 - val_loss: 0.5123 - val_acc: 0.7560\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.4388 - acc: 0.7945 - val_loss: 0.4844 - val_acc: 0.7680\n",
      "Epoch 30/30\n",
      "80/80 [==============================] - 9s 114ms/step - loss: 0.4264 - acc: 0.7984 - val_loss: 0.5091 - val_acc: 0.7600\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,steps_per_epoch=80,epochs=30,validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(20,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=0.0001),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 51s 327ms/step - loss: 0.6930 - acc: 0.5330 - val_loss: 0.6900 - val_acc: 0.5930\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 25s 311ms/step - loss: 0.6914 - acc: 0.5265 - val_loss: 0.6795 - val_acc: 0.5840\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 22s 272ms/step - loss: 0.6806 - acc: 0.5530 - val_loss: 0.6663 - val_acc: 0.5810\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 22s 277ms/step - loss: 0.6786 - acc: 0.5899 - val_loss: 0.6710 - val_acc: 0.5470\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 21s 256ms/step - loss: 0.6743 - acc: 0.5937 - val_loss: 0.6511 - val_acc: 0.6360\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 21s 256ms/step - loss: 0.6616 - acc: 0.5992 - val_loss: 0.6462 - val_acc: 0.6040\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 19s 233ms/step - loss: 0.6653 - acc: 0.5954 - val_loss: 0.6337 - val_acc: 0.6510\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 21s 265ms/step - loss: 0.6520 - acc: 0.6156 - val_loss: 0.6206 - val_acc: 0.6510\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 18s 225ms/step - loss: 0.6536 - acc: 0.6041 - val_loss: 0.6194 - val_acc: 0.6360\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 18s 226ms/step - loss: 0.6500 - acc: 0.6022 - val_loss: 0.6210 - val_acc: 0.6540\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 17s 214ms/step - loss: 0.6285 - acc: 0.6260 - val_loss: 0.6109 - val_acc: 0.6510\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 17s 212ms/step - loss: 0.6396 - acc: 0.6223 - val_loss: 0.5891 - val_acc: 0.6870\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 17s 216ms/step - loss: 0.6408 - acc: 0.6342 - val_loss: 0.6040 - val_acc: 0.6570\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 17s 214ms/step - loss: 0.6294 - acc: 0.6378 - val_loss: 0.5840 - val_acc: 0.6910\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 17s 211ms/step - loss: 0.6156 - acc: 0.6612 - val_loss: 0.5782 - val_acc: 0.6930\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 17s 211ms/step - loss: 0.6079 - acc: 0.6701 - val_loss: 0.5683 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 17s 214ms/step - loss: 0.6171 - acc: 0.6468 - val_loss: 0.5756 - val_acc: 0.6950\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 17s 217ms/step - loss: 0.6111 - acc: 0.6577 - val_loss: 0.5659 - val_acc: 0.6950\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 17s 210ms/step - loss: 0.5992 - acc: 0.6744 - val_loss: 0.5593 - val_acc: 0.7090\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 17s 210ms/step - loss: 0.5776 - acc: 0.7020 - val_loss: 0.5625 - val_acc: 0.7080\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 17s 210ms/step - loss: 0.5996 - acc: 0.6747 - val_loss: 0.5843 - val_acc: 0.6800\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 17s 212ms/step - loss: 0.6123 - acc: 0.6558 - val_loss: 0.5427 - val_acc: 0.7150\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 17s 215ms/step - loss: 0.5749 - acc: 0.7024 - val_loss: 0.5416 - val_acc: 0.7190\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 19s 236ms/step - loss: 0.5942 - acc: 0.6813 - val_loss: 0.5522 - val_acc: 0.7010\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 19s 241ms/step - loss: 0.6078 - acc: 0.6403 - val_loss: 0.5494 - val_acc: 0.7100\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 18s 219ms/step - loss: 0.6023 - acc: 0.6768 - val_loss: 0.5452 - val_acc: 0.7190\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 17s 214ms/step - loss: 0.5775 - acc: 0.6993 - val_loss: 0.5428 - val_acc: 0.7340\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 17s 215ms/step - loss: 0.5749 - acc: 0.7122 - val_loss: 0.5672 - val_acc: 0.6940\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 18s 221ms/step - loss: 0.5966 - acc: 0.6989 - val_loss: 0.5333 - val_acc: 0.7280\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 17s 216ms/step - loss: 0.5508 - acc: 0.7174 - val_loss: 0.5384 - val_acc: 0.7220\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 18s 224ms/step - loss: 0.5657 - acc: 0.6872 - val_loss: 0.5544 - val_acc: 0.6910\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 18s 221ms/step - loss: 0.5803 - acc: 0.7006 - val_loss: 0.5295 - val_acc: 0.7390\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 19s 234ms/step - loss: 0.5672 - acc: 0.7001 - val_loss: 0.5165 - val_acc: 0.7380\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 20s 255ms/step - loss: 0.5771 - acc: 0.7043 - val_loss: 0.5271 - val_acc: 0.7420\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 20s 249ms/step - loss: 0.5902 - acc: 0.6869 - val_loss: 0.5200 - val_acc: 0.7300\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 18s 228ms/step - loss: 0.5882 - acc: 0.6922 - val_loss: 0.5402 - val_acc: 0.7190\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 20s 256ms/step - loss: 0.5596 - acc: 0.6936 - val_loss: 0.5822 - val_acc: 0.6930\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 20s 246ms/step - loss: 0.5708 - acc: 0.7104 - val_loss: 0.5439 - val_acc: 0.7070\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 18s 222ms/step - loss: 0.5519 - acc: 0.7201 - val_loss: 0.5165 - val_acc: 0.7260\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.5740 - acc: 0.6926 - val_loss: 0.5036 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 18s 225ms/step - loss: 0.5770 - acc: 0.6915 - val_loss: 0.4973 - val_acc: 0.7460\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 19s 243ms/step - loss: 0.5358 - acc: 0.7355 - val_loss: 0.5210 - val_acc: 0.7310\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 19s 236ms/step - loss: 0.5773 - acc: 0.6813 - val_loss: 0.5311 - val_acc: 0.7270\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 21s 264ms/step - loss: 0.5418 - acc: 0.7244 - val_loss: 0.5295 - val_acc: 0.7320\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 25s 307ms/step - loss: 0.5276 - acc: 0.7236 - val_loss: 0.5115 - val_acc: 0.7450\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 26s 328ms/step - loss: 0.5541 - acc: 0.7284 - val_loss: 0.5319 - val_acc: 0.7300\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 25s 311ms/step - loss: 0.5330 - acc: 0.7076 - val_loss: 0.4927 - val_acc: 0.7470\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 22s 279ms/step - loss: 0.5466 - acc: 0.7177 - val_loss: 0.5104 - val_acc: 0.7440\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 0.5715 - acc: 0.6850 - val_loss: 0.5352 - val_acc: 0.7260\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 19s 232ms/step - loss: 0.5354 - acc: 0.7394 - val_loss: 0.5224 - val_acc: 0.7260\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 18s 223ms/step - loss: 0.5357 - acc: 0.7346 - val_loss: 0.4953 - val_acc: 0.7560\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 18s 220ms/step - loss: 0.5479 - acc: 0.7309 - val_loss: 0.4984 - val_acc: 0.7530\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 18s 219ms/step - loss: 0.5238 - acc: 0.7476 - val_loss: 0.4874 - val_acc: 0.7460\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 18s 223ms/step - loss: 0.5185 - acc: 0.7431 - val_loss: 0.4840 - val_acc: 0.7550\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 17s 218ms/step - loss: 0.5478 - acc: 0.7242 - val_loss: 0.4793 - val_acc: 0.7670\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 17s 217ms/step - loss: 0.5351 - acc: 0.7421 - val_loss: 0.4977 - val_acc: 0.7470\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 17s 218ms/step - loss: 0.5237 - acc: 0.7283 - val_loss: 0.4713 - val_acc: 0.7660\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 17s 218ms/step - loss: 0.5415 - acc: 0.7314 - val_loss: 0.4913 - val_acc: 0.7630\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 18s 222ms/step - loss: 0.5293 - acc: 0.7186 - val_loss: 0.4880 - val_acc: 0.7480\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 18s 220ms/step - loss: 0.5248 - acc: 0.7339 - val_loss: 0.5141 - val_acc: 0.7390\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 18s 219ms/step - loss: 0.5066 - acc: 0.7521 - val_loss: 0.4723 - val_acc: 0.7690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "80/80 [==============================] - 18s 222ms/step - loss: 0.5299 - acc: 0.7470 - val_loss: 0.5216 - val_acc: 0.7320\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 18s 227ms/step - loss: 0.5185 - acc: 0.7460 - val_loss: 0.4711 - val_acc: 0.7690\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 18s 222ms/step - loss: 0.5182 - acc: 0.7335 - val_loss: 0.4688 - val_acc: 0.7770\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 18s 222ms/step - loss: 0.5086 - acc: 0.7450 - val_loss: 0.4706 - val_acc: 0.7620\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 18s 223ms/step - loss: 0.5278 - acc: 0.7206 - val_loss: 0.4920 - val_acc: 0.7460\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 17s 218ms/step - loss: 0.5516 - acc: 0.7074 - val_loss: 0.4686 - val_acc: 0.7700\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 18s 221ms/step - loss: 0.5384 - acc: 0.7259 - val_loss: 0.4567 - val_acc: 0.7710\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 18s 219ms/step - loss: 0.5235 - acc: 0.7326 - val_loss: 0.4689 - val_acc: 0.7750\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 18s 222ms/step - loss: 0.5235 - acc: 0.7300 - val_loss: 0.5104 - val_acc: 0.7390\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 18s 220ms/step - loss: 0.5388 - acc: 0.7295 - val_loss: 0.5117 - val_acc: 0.7320\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 18s 222ms/step - loss: 0.5445 - acc: 0.7182 - val_loss: 0.4791 - val_acc: 0.7650\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 19s 240ms/step - loss: 0.5081 - acc: 0.7413 - val_loss: 0.4854 - val_acc: 0.7490\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 18s 231ms/step - loss: 0.5385 - acc: 0.7272 - val_loss: 0.4665 - val_acc: 0.7690\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 18s 226ms/step - loss: 0.5150 - acc: 0.7496 - val_loss: 0.4545 - val_acc: 0.7770\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 18s 227ms/step - loss: 0.5331 - acc: 0.7348 - val_loss: 0.4884 - val_acc: 0.7540\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 19s 243ms/step - loss: 0.5309 - acc: 0.7256 - val_loss: 0.4834 - val_acc: 0.7530\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 19s 240ms/step - loss: 0.5163 - acc: 0.7446 - val_loss: 0.4582 - val_acc: 0.7720\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 19s 232ms/step - loss: 0.5042 - acc: 0.7431 - val_loss: 0.4552 - val_acc: 0.7760\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 19s 238ms/step - loss: 0.5193 - acc: 0.7459 - val_loss: 0.4481 - val_acc: 0.7890\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 20s 246ms/step - loss: 0.5095 - acc: 0.7418 - val_loss: 0.4757 - val_acc: 0.7610\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 18s 228ms/step - loss: 0.5384 - acc: 0.7298 - val_loss: 0.4504 - val_acc: 0.7860\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 20s 247ms/step - loss: 0.5227 - acc: 0.7375 - val_loss: 0.4498 - val_acc: 0.7800\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 20s 245ms/step - loss: 0.5060 - acc: 0.7575 - val_loss: 0.4430 - val_acc: 0.7930\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 20s 244ms/step - loss: 0.5284 - acc: 0.7422 - val_loss: 0.4642 - val_acc: 0.7750\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 18s 223ms/step - loss: 0.4875 - acc: 0.7607 - val_loss: 0.4879 - val_acc: 0.7530\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 18s 222ms/step - loss: 0.4658 - acc: 0.7765 - val_loss: 0.5125 - val_acc: 0.7400\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 18s 221ms/step - loss: 0.5115 - acc: 0.7543 - val_loss: 0.4554 - val_acc: 0.7850\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 18s 224ms/step - loss: 0.4773 - acc: 0.7716 - val_loss: 0.4414 - val_acc: 0.7890\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 17s 217ms/step - loss: 0.4970 - acc: 0.7526 - val_loss: 0.4452 - val_acc: 0.7960\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 18s 226ms/step - loss: 0.5147 - acc: 0.7513 - val_loss: 0.4460 - val_acc: 0.7840\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 19s 243ms/step - loss: 0.5219 - acc: 0.7433 - val_loss: 0.4851 - val_acc: 0.7520\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 21s 267ms/step - loss: 0.4983 - acc: 0.7688 - val_loss: 0.4436 - val_acc: 0.7860\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 18s 228ms/step - loss: 0.5044 - acc: 0.7380 - val_loss: 0.4510 - val_acc: 0.7820\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 18s 220ms/step - loss: 0.4855 - acc: 0.7695 - val_loss: 0.4957 - val_acc: 0.7440\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 19s 237ms/step - loss: 0.5088 - acc: 0.7451 - val_loss: 0.4793 - val_acc: 0.7640\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 18s 220ms/step - loss: 0.4731 - acc: 0.7721 - val_loss: 0.4413 - val_acc: 0.7800\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 17s 217ms/step - loss: 0.5150 - acc: 0.7340 - val_loss: 0.4499 - val_acc: 0.7830\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 17s 214ms/step - loss: 0.5156 - acc: 0.7433 - val_loss: 0.4396 - val_acc: 0.7870\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 17s 218ms/step - loss: 0.5065 - acc: 0.7563 - val_loss: 0.4308 - val_acc: 0.7920\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,steps_per_epoch=80,epochs=100,validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory,sample_count):\n",
    "    features = np.zeros(shape=(sample_count,4,4,512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(directory,target_size=(150,150),batch_size=batch_size,class_mode='binary')\n",
    "    i = 0\n",
    "    for input_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(input_batch)\n",
    "        features[i*batch_size : (i+1)*batch_size] = features_batch\n",
    "        labels[i*batch_size : (i+1)*batch_size] =labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_features, validation_labels = extract_features(validation_dir,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = extract_features(test_dir,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features,(2000,4*4*512))\n",
    "validation_features = np.reshape(validation_features,(1000,4*4*512))\n",
    "test_features = np.reshape(test_features,(1000,4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256,activation='relu',input_dim=4*4*512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=0.00002),loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 3s 15ms/step - loss: 0.6811 - acc: 0.6132 - val_loss: 0.4309 - val_acc: 0.8370\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.4583 - acc: 0.7875 - val_loss: 0.3646 - val_acc: 0.8520\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.3575 - acc: 0.8475 - val_loss: 0.3310 - val_acc: 0.8650\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.3341 - acc: 0.8556 - val_loss: 0.3151 - val_acc: 0.8690\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2956 - acc: 0.8812 - val_loss: 0.2978 - val_acc: 0.8780\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2712 - acc: 0.8858 - val_loss: 0.2873 - val_acc: 0.8800\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2588 - acc: 0.8917 - val_loss: 0.2848 - val_acc: 0.8800\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2415 - acc: 0.9056 - val_loss: 0.2735 - val_acc: 0.8860\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2440 - acc: 0.8988 - val_loss: 0.2710 - val_acc: 0.8830\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2175 - acc: 0.9116 - val_loss: 0.2669 - val_acc: 0.8860\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2046 - acc: 0.9208 - val_loss: 0.2623 - val_acc: 0.8850\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1950 - acc: 0.9257 - val_loss: 0.2589 - val_acc: 0.8850\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2025 - acc: 0.9276 - val_loss: 0.2646 - val_acc: 0.8870\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1841 - acc: 0.9321 - val_loss: 0.2563 - val_acc: 0.8870\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1739 - acc: 0.9350 - val_loss: 0.2549 - val_acc: 0.8860\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1736 - acc: 0.9399 - val_loss: 0.2556 - val_acc: 0.8870\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1600 - acc: 0.9476 - val_loss: 0.2554 - val_acc: 0.8890\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1537 - acc: 0.9450 - val_loss: 0.2520 - val_acc: 0.8840\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1499 - acc: 0.9511 - val_loss: 0.2653 - val_acc: 0.8830\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1418 - acc: 0.9446 - val_loss: 0.2547 - val_acc: 0.8910\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1295 - acc: 0.9600 - val_loss: 0.2497 - val_acc: 0.8900\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1307 - acc: 0.9555 - val_loss: 0.2522 - val_acc: 0.8870\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1198 - acc: 0.9620 - val_loss: 0.2531 - val_acc: 0.8940\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1197 - acc: 0.9584 - val_loss: 0.2644 - val_acc: 0.8880\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1196 - acc: 0.9581 - val_loss: 0.2500 - val_acc: 0.8890\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1206 - acc: 0.9625 - val_loss: 0.2495 - val_acc: 0.8910\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1155 - acc: 0.9594 - val_loss: 0.2521 - val_acc: 0.8920\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1032 - acc: 0.9674 - val_loss: 0.2536 - val_acc: 0.8920\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.0970 - acc: 0.9689 - val_loss: 0.2511 - val_acc: 0.8920\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.0938 - acc: 0.9731 - val_loss: 0.2538 - val_acc: 0.8900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features,train_labels,epochs=30,batch_size=20,validation_data=(validation_features,validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plots_(train,val,metric):\n",
    "    epochs = range(1,len(train)+1)\n",
    "    plt.plot(epochs,train,'bo',label='Training %s'%(metric))\n",
    "    plt.plot(epochs,val,'ro',label='Validation %s'%(metric))\n",
    "    plt.title('Training and Validation %s'%(metric))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plots_(acc,val_acc,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=0.00002),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 100s 738ms/step - loss: 0.6564 - acc: 0.6005 - val_loss: 0.4959 - val_acc: 0.7690\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 56s 695ms/step - loss: 0.5202 - acc: 0.7590 - val_loss: 0.4063 - val_acc: 0.8240\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 58s 721ms/step - loss: 0.4583 - acc: 0.7885 - val_loss: 0.3705 - val_acc: 0.8390\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 62s 773ms/step - loss: 0.4331 - acc: 0.8100 - val_loss: 0.3405 - val_acc: 0.8460\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 62s 776ms/step - loss: 0.3949 - acc: 0.8182 - val_loss: 0.3188 - val_acc: 0.8510\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 63s 781ms/step - loss: 0.3909 - acc: 0.8178 - val_loss: 0.3299 - val_acc: 0.8570\n",
      "Epoch 7/30\n",
      "80/80 [==============================] - 70s 872ms/step - loss: 0.3933 - acc: 0.8264 - val_loss: 0.2944 - val_acc: 0.8710\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 57s 712ms/step - loss: 0.3487 - acc: 0.8478 - val_loss: 0.2950 - val_acc: 0.8740\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 67s 842ms/step - loss: 0.3757 - acc: 0.8256 - val_loss: 0.3177 - val_acc: 0.8630\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 70s 874ms/step - loss: 0.3770 - acc: 0.8267 - val_loss: 0.2772 - val_acc: 0.8820\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 65s 816ms/step - loss: 0.3560 - acc: 0.8329 - val_loss: 0.2994 - val_acc: 0.8750\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 57s 711ms/step - loss: 0.3453 - acc: 0.8388 - val_loss: 0.2733 - val_acc: 0.8840\n",
      "Epoch 13/30\n",
      "80/80 [==============================] - 68s 851ms/step - loss: 0.3269 - acc: 0.8685 - val_loss: 0.2674 - val_acc: 0.8840\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 67s 840ms/step - loss: 0.3451 - acc: 0.8542 - val_loss: 0.2973 - val_acc: 0.8720\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 66s 829ms/step - loss: 0.3557 - acc: 0.8397 - val_loss: 0.3125 - val_acc: 0.8600\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 68s 854ms/step - loss: 0.3355 - acc: 0.8451 - val_loss: 0.2591 - val_acc: 0.8890\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 68s 853ms/step - loss: 0.3092 - acc: 0.8584 - val_loss: 0.2762 - val_acc: 0.8860\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 69s 871ms/step - loss: 0.3143 - acc: 0.8690 - val_loss: 0.2613 - val_acc: 0.8950\n",
      "Epoch 19/30\n",
      "80/80 [==============================] - 73s 917ms/step - loss: 0.3577 - acc: 0.8448 - val_loss: 0.2491 - val_acc: 0.8890\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 68s 843ms/step - loss: 0.3252 - acc: 0.8537 - val_loss: 0.2611 - val_acc: 0.8910\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 75s 942ms/step - loss: 0.3333 - acc: 0.8515 - val_loss: 0.2584 - val_acc: 0.8940\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 69s 867ms/step - loss: 0.3084 - acc: 0.8637 - val_loss: 0.2613 - val_acc: 0.8920\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 68s 859ms/step - loss: 0.3248 - acc: 0.8587 - val_loss: 0.2466 - val_acc: 0.8920\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 70s 884ms/step - loss: 0.2876 - acc: 0.8694 - val_loss: 0.2487 - val_acc: 0.8860\n",
      "Epoch 25/30\n",
      "80/80 [==============================] - 73s 918ms/step - loss: 0.3230 - acc: 0.8557 - val_loss: 0.2482 - val_acc: 0.8940\n",
      "Epoch 26/30\n",
      "80/80 [==============================] - 72s 902ms/step - loss: 0.3263 - acc: 0.8619 - val_loss: 0.2481 - val_acc: 0.8970\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 73s 913ms/step - loss: 0.3280 - acc: 0.8523 - val_loss: 0.2510 - val_acc: 0.9000\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 75s 947ms/step - loss: 0.3134 - acc: 0.8665 - val_loss: 0.2410 - val_acc: 0.8980\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 75s 939ms/step - loss: 0.2911 - acc: 0.8792 - val_loss: 0.2401 - val_acc: 0.8990\n",
      "Epoch 30/30\n",
      "80/80 [==============================] - 75s 945ms/step - loss: 0.2890 - acc: 0.8641 - val_loss: 0.2378 - val_acc: 0.8990\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,steps_per_epoch=80,epochs=30,validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_plots_(acc,val_acc,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=0.00001),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 116s 772ms/step - loss: 0.6035 - acc: 0.6500 - val_loss: 0.3490 - val_acc: 0.8480\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 74s 737ms/step - loss: 0.4256 - acc: 0.8101 - val_loss: 0.2968 - val_acc: 0.8750\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 75s 751ms/step - loss: 0.3525 - acc: 0.8461 - val_loss: 0.2391 - val_acc: 0.8930\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 75s 748ms/step - loss: 0.3026 - acc: 0.8656 - val_loss: 0.2663 - val_acc: 0.8940\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 84s 840ms/step - loss: 0.2662 - acc: 0.8945 - val_loss: 0.2108 - val_acc: 0.9130\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 83s 835ms/step - loss: 0.2591 - acc: 0.8828 - val_loss: 0.2034 - val_acc: 0.9120\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 86s 865ms/step - loss: 0.2552 - acc: 0.8870 - val_loss: 0.2206 - val_acc: 0.9210\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 87s 871ms/step - loss: 0.2546 - acc: 0.8979 - val_loss: 0.1807 - val_acc: 0.9340\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 87s 875ms/step - loss: 0.2260 - acc: 0.8982 - val_loss: 0.1944 - val_acc: 0.9330\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 89s 891ms/step - loss: 0.2143 - acc: 0.9187 - val_loss: 0.2239 - val_acc: 0.9140\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 99s 987ms/step - loss: 0.2045 - acc: 0.9186 - val_loss: 0.1676 - val_acc: 0.9290\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 90s 903ms/step - loss: 0.2079 - acc: 0.9115 - val_loss: 0.1640 - val_acc: 0.9310\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.2083 - acc: 0.9093 - val_loss: 0.1647 - val_acc: 0.9330\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 90s 906ms/step - loss: 0.1940 - acc: 0.9156 - val_loss: 0.2145 - val_acc: 0.9350\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.2004 - acc: 0.9098 - val_loss: 0.1524 - val_acc: 0.9450\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 93s 931ms/step - loss: 0.1798 - acc: 0.9227 - val_loss: 0.1490 - val_acc: 0.9410\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.1913 - acc: 0.9171 - val_loss: 0.1531 - val_acc: 0.9430\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 98s 984ms/step - loss: 0.1699 - acc: 0.9239 - val_loss: 0.2573 - val_acc: 0.9160\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 97s 968ms/step - loss: 0.1767 - acc: 0.9296 - val_loss: 0.1872 - val_acc: 0.9360\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 99s 990ms/step - loss: 0.1702 - acc: 0.9217 - val_loss: 0.1686 - val_acc: 0.9330\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.1601 - acc: 0.9319 - val_loss: 0.1948 - val_acc: 0.9370\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 93s 934ms/step - loss: 0.1827 - acc: 0.9209 - val_loss: 0.1588 - val_acc: 0.9410\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.1644 - acc: 0.9235 - val_loss: 0.1646 - val_acc: 0.9420\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.1667 - acc: 0.9299 - val_loss: 0.1561 - val_acc: 0.9470\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.1500 - acc: 0.9436 - val_loss: 0.1445 - val_acc: 0.9470\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 91s 910ms/step - loss: 0.1712 - acc: 0.9327 - val_loss: 0.1432 - val_acc: 0.9490\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.1431 - acc: 0.9401 - val_loss: 0.1535 - val_acc: 0.9500\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 0.1523 - acc: 0.9370 - val_loss: 0.1660 - val_acc: 0.9440\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.1418 - acc: 0.9522 - val_loss: 0.1812 - val_acc: 0.9460\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.1335 - acc: 0.9414 - val_loss: 0.1709 - val_acc: 0.9440\n",
      "Epoch 31/100\n",
      " 18/100 [====>.........................] - ETA: 45s - loss: 0.1543 - acc: 0.9440"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8247f07fd56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(train_generator,steps_per_epoch=100,epochs=100,validation_data=validation_generator,\n\u001b[0;32m----> 2\u001b[0;31m                              validation_steps=50)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,steps_per_epoch=100,epochs=100,validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
